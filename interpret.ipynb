{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import seed_torch, get_best_model_path\n",
    "from dataclasses import dataclass\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from experiment.tft import Experiment_TFT\n",
    "from explainers import *\n",
    "from experiment.config import Split, DataConfig, FeatureFiles\n",
    "from utils.interpreter import *\n",
    "from utils.plotter import PlotResults\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class args:\n",
    "    result_folder = 'scratch/no_scale/' # 'results/Top_100'\n",
    "    input_folder = 'dataset/processed/'\n",
    "    input = 'Top_100.csv'\n",
    "    explainer = 'FO'\n",
    "    \n",
    "    disable_progress = False\n",
    "    seed = 7\n",
    "    \n",
    "seed_torch(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainer_factory(\n",
    "    args, model, dataloader:AgeDataLoader, \n",
    ")-> BaseExplainer:\n",
    "    # only interpreting static reals for now\n",
    "    features = dataloader.static_reals\n",
    "    \n",
    "    if args.explainer == 'FO':\n",
    "        explainer = FeatureOcclusion(model, dataloader, features)\n",
    "    elif args.explainer == 'AFO':\n",
    "        explainer = AugmentedFeatureOcclusion(model, dataloader, features, n_samples=2)\n",
    "    elif args.explainer == 'FA':\n",
    "        explainer = FeatureAblation(model, dataloader, features, method='global')\n",
    "    else:\n",
    "        raise ValueError(f'{args.explainer} isn\\'t supported.')\n",
    "    return explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103600, 13)\n",
      "        Date  FIPS  UNDER5  AGE517  AGE1829  AGE3039  AGE4049  AGE5064  \\\n",
      "0 2020-12-13  2261  0.0062   0.016    0.014   0.0146   0.0117   0.0235   \n",
      "1 2020-12-14  2261  0.0062   0.016    0.014   0.0146   0.0117   0.0235   \n",
      "2 2020-12-15  2261  0.0062   0.016    0.014   0.0146   0.0117   0.0235   \n",
      "\n",
      "   AGE6574  AGE75PLUS  VaccinationFull  Cases  SinWeekly  \n",
      "0   0.0103     0.0004              0.0    2.0    -0.7818  \n",
      "1   0.0103     0.0004              0.0    1.0     0.0000  \n",
      "2   0.0103     0.0004              0.0    1.0     0.7818  \n",
      "\n",
      "Train samples 63700, validation samples 2800, test samples 2800\n",
      "637 days of training, 14 days of validation data, 14 days of test data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(args.input_folder, args.input)\n",
    "experiment = Experiment_TFT(\n",
    "    data_path, args.result_folder, not args.disable_progress\n",
    ")\n",
    "\n",
    "total_data = experiment.age_dataloader.read_df()\n",
    "print(total_data.shape)\n",
    "print(total_data.head(3))\n",
    "\n",
    "train_data, val_data, test_data = experiment.age_dataloader.split_data(\n",
    "    total_data, Split.primary()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = experiment.age_dataloader\n",
    "time_index = dataloader.time_index\n",
    "features = dataloader.static_reals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found best checkpoint model best-epoch=5.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\utilities\\parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\mi3se\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\utilities\\parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model_path = get_best_model_path(args.result_folder)\n",
    "model = TemporalFusionTransformer.load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [12:12<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "explainer = explainer_factory(args, model, dataloader)\n",
    "\n",
    "# train any baseline or parameters\n",
    "explainer.train_generators(train_data)\n",
    "all_scores = explainer.attribute(train_data, args.disable_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_file = os.path.join(args.result_folder, 'scores.npy.gz')\n",
    "np.savez_compressed(score_file, all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = dataloader.time_index\n",
    "features = dataloader.static_reals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = explainer.time_range(train_data)\n",
    "df = data[\n",
    "    (data[time_index]>=time_range[0]) & \n",
    "    (data[time_index]<=time_range[-1])\n",
    "][['Date', 'FIPS']]\n",
    "\n",
    "global_rank = calculate_global_rank(\n",
    "    df, all_scores, features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_agg_scores_df = align_interpretation(df, all_scores, features)\n",
    "\n",
    "# plot local interpretations\n",
    "plotter = PlotResults(\n",
    "    figPath=args.result_folder, targets=dataloader.targets, \n",
    "    show=not args.disable_progress\n",
    ")\n",
    "plotter.local_interpretation(\n",
    "    group_agg_scores_df, dataloader.static_reals\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "group_cases = pd.read_csv(\n",
    "    os.path.join(FeatureFiles.root_folder, 'Cases by age groups.csv')\n",
    ")\n",
    "group_cases['end_of_week'] = pd.to_datetime(group_cases['end_of_week'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate rank score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a common start point\n",
    "first_common_date = find_first_common_date(\n",
    "    group_cases, group_agg_scores_df['Date'].values\n",
    ")\n",
    "\n",
    "# since age group ground truth is weekly aggregated\n",
    "# do the same for predicted importance\n",
    "weekly_agg_scores_df = aggregate_importance_by_window(\n",
    "    group_agg_scores_df, dataloader.static_reals, first_common_date\n",
    ")\n",
    "evaluate_interpretation(\n",
    "    group_cases, weekly_agg_scores_df, dataloader.static_reals\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
