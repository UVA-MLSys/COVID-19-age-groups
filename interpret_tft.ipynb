{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import seed_torch, get_best_model_path\n",
    "from pytorch_forecasting import TemporalFusionTransformer\n",
    "from exp.exp_tft import Experiment_TFT\n",
    "from exp.config import Split, FeatureFiles\n",
    "from utils.interpreter import *\n",
    "from utils.plotter import PlotResults\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import gc, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_tft import get_argparser, stringify_setting\n",
    "\n",
    "argv = \"\"\"\n",
    "--result_path scratch\n",
    "--data_path Top_20.csv\n",
    "--test\n",
    "\"\"\".split()\n",
    "args = get_argparser().parse_args(argv)\n",
    "\n",
    "args.explainer = 'FO'\n",
    "seed_torch(args.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = stringify_setting(args)\n",
    "experiment = Experiment_TFT(args, setting)\n",
    "\n",
    "total_data = experiment.age_dataloader.read_df()\n",
    "print(total_data.shape)\n",
    "print(total_data.head(3))\n",
    "\n",
    "train_data, val_data, test_data = experiment.age_dataloader.split_data(\n",
    "    total_data, Split.primary()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_data = experiment.age_dataloader\n",
    "time_index = age_data.time_index\n",
    "features = age_data.static_reals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = get_best_model_path(experiment.output_folder)\n",
    "model = TemporalFusionTransformer.load_from_checkpoint(model_path, map_location=device)\n",
    "_ = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple, Dict\n",
    "\n",
    "class OutputMixIn:\n",
    "    \"\"\"\n",
    "    MixIn to give namedtuple some access capabilities of a dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        if isinstance(k, str):\n",
    "            return getattr(self, k)\n",
    "        else:\n",
    "            return super().__getitem__(k)\n",
    "\n",
    "    def get(self, k, default=None):\n",
    "        return getattr(self, k, default)\n",
    "\n",
    "    def items(self):\n",
    "        return zip(self._fields, self)\n",
    "\n",
    "    def keys(self):\n",
    "        return self._fields\n",
    "\n",
    "    def iget(self, idx: Union[int, slice]):\n",
    "        \"\"\"Select item(s) row-wise.\n",
    "\n",
    "        Args:\n",
    "            idx ([int, slice]): item to select\n",
    "\n",
    "        Returns:\n",
    "            Output of single item.\n",
    "        \"\"\"\n",
    "        return self.__class__(*(x[idx] for x in self))\n",
    "\n",
    "def move_to_device(\n",
    "    x: Union[\n",
    "        Dict[str, Union[torch.Tensor, List[torch.Tensor], Tuple[torch.Tensor]]],\n",
    "        torch.Tensor,\n",
    "        List[torch.Tensor],\n",
    "        Tuple[torch.Tensor],\n",
    "    ],\n",
    "    device: Union[str, torch.DeviceObjType],\n",
    ") -> Union[\n",
    "    Dict[str, Union[torch.Tensor, List[torch.Tensor], Tuple[torch.Tensor]]],\n",
    "    torch.Tensor,\n",
    "    List[torch.Tensor],\n",
    "    Tuple[torch.Tensor],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Move object to device.\n",
    "\n",
    "    Args:\n",
    "        x (dictionary of list of tensors): object (e.g. dictionary) of tensors to move to device\n",
    "        device (Union[str, torch.DeviceObjType]): device, e.g. \"cpu\"\n",
    "\n",
    "    Returns:\n",
    "        x on targeted device\n",
    "    \"\"\"\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "    if isinstance(x, dict):\n",
    "        for name in x.keys():\n",
    "            x[name] = move_to_device(x[name], device=device)\n",
    "    elif isinstance(x, OutputMixIn):\n",
    "        for xi in x:\n",
    "            move_to_device(xi, device=device)\n",
    "        return x\n",
    "    elif isinstance(x, torch.Tensor) and x.device != device:\n",
    "        x = x.to(device)\n",
    "    elif isinstance(x, (list, tuple)) and x[0].device != device:\n",
    "        x = [move_to_device(xi, device=device) for xi in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataloader = age_data.create_timeseries(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list = []\n",
    "for (x, _) in tqdm(dataloader):\n",
    "    x = move_to_device(x, device)\n",
    "    \n",
    "    # batch_size x seq_len x features\n",
    "    inputs = x['encoder_cont']\n",
    "    assignment = torch.randn(inputs.shape[0], device=inputs.device)\n",
    "    \n",
    "    # passing target name in a list during training \n",
    "    # returns prediction as a list despite having one target\n",
    "    # list of batch_size x pred_len x 1\n",
    "    y_pred = model(x)['prediction'][0]\n",
    "    \n",
    "    attr = torch.zeros_like(inputs, device=inputs.device)\n",
    "    for t in range(args.seq_len):\n",
    "        for f in range(len(features)):\n",
    "            x_hat = inputs.clone()\n",
    "            x_hat[:, t, f] = assignment\n",
    "            x['encoder_cont'] = x_hat\n",
    "            \n",
    "            y_pred_hat = model(x)['prediction'][0]\n",
    "            attr[:, t, f] = torch.sum(torch.abs(y_pred_hat - y_pred), dim=(1, 2))\n",
    "            \n",
    "    attr_list.append(attr)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "attr = torch.vstack(attr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = attr.detach().cpu().numpy()\n",
    "group_agg_scores_df = align_interpretation(df, all_scores, features)\n",
    "\n",
    "# plot local interpretations\n",
    "plotter = PlotResults(\n",
    "    figPath=args.result_folder, targets=dataloader.targets, \n",
    "    show=not args.disable_progress\n",
    ")\n",
    "plotter.local_interpretation(\n",
    "    group_agg_scores_df, dataloader.static_reals\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "The white box evaluation is only available for age group features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "group_cases = pd.read_csv(\n",
    "    os.path.join(FeatureFiles.root_folder, 'Cases by age groups.csv')\n",
    ")\n",
    "group_cases['end_of_week'] = pd.to_datetime(group_cases['end_of_week'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate rank score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a common start point\n",
    "first_common_date = find_first_common_date(\n",
    "    group_cases, group_agg_scores_df['Date'].values\n",
    ")\n",
    "\n",
    "# since age group ground truth is weekly aggregated\n",
    "# do the same for predicted importance\n",
    "weekly_agg_scores_df = aggregate_importance_by_window(\n",
    "    group_agg_scores_df, dataloader.static_reals, first_common_date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_interpretation(\n",
    "    group_cases, weekly_agg_scores_df, dataloader.static_reals\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
