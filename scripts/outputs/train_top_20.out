bash: /u/mi3se/anaconda3/envs/ml/lib/libtinfo.so.6: no version information available (required by bash)
2023-09-25 21:30:53.819031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-25 21:30:57.332344: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-09-25 21:31:02.855960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/ubuntu-22.04/anaconda3/current/lib:/sw/ubuntu-22.04/cudnn/current/lib:/sw/ubuntu-22.04/cuda/current/extras/CUPTI/lib64:/sw/ubuntu-22.04/cuda/current/lib64::/u/mi3se/anaconda3/envs/ml/lib/:/u/mi3se/anaconda3/envs/ml/lib/
2023-09-25 21:31:02.857221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/ubuntu-22.04/anaconda3/current/lib:/sw/ubuntu-22.04/cudnn/current/lib:/sw/ubuntu-22.04/cuda/current/extras/CUPTI/lib64:/sw/ubuntu-22.04/cuda/current/lib64::/u/mi3se/anaconda3/envs/ml/lib/:/u/mi3se/anaconda3/envs/ml/lib/
2023-09-25 21:31:02.857241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Args in experiment:
Namespace(test=False, model='DLinear', seed=7, root_path='./dataset/processed/', data_path='Top_20.csv', result_path='results', freq='d', no_scale=False, seq_len=14, label_len=7, pred_len=14, top_k=5, num_kernels=6, d_model=64, n_heads=4, e_layers=2, d_layers=1, d_ff=256, moving_avg=7, factor=3, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=0, train_epochs=10, batch_size=32, patience=3, learning_rate=0.001, des='', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[64, 64], p_hidden_layers=2, n_features=10, enc_in=10, dec_in=10, c_out=10, n_targets=1)
Use GPU: cuda:0

Train samples 12740, validation samples 560, test samples 560
637 days of training, 14 days of validation data, 14 days of test data.

Fitting scalers on train data
Loading dataset from ./dataset/processed/Top_20/train.pt
Loading dataset from ./dataset/processed/Top_20/val.pt
Loading dataset from ./dataset/processed/Top_20/test.pt
>>>>>>> training : DLinear_Top_20 >>>>>>>>>
Epoch: 1 cost time: 1.3192
Epoch: 1, Steps: 191 | Train Loss: 0.38909 Vali Loss: 0.42371
Validation loss decreased (inf -> 0.42371). Saving model ...
Epoch: 2 cost time: 0.65799
Epoch: 2, Steps: 191 | Train Loss: 0.34974 Vali Loss: 0.38204
Validation loss decreased (0.42371 -> 0.38204). Saving model ...
Epoch: 3 cost time: 0.65882
Epoch: 3, Steps: 191 | Train Loss: 0.3318 Vali Loss: 0.36012
Validation loss decreased (0.38204 -> 0.36012). Saving model ...
Epoch: 4 cost time: 0.66358
Epoch: 4, Steps: 191 | Train Loss: 0.31965 Vali Loss: 0.34694
Validation loss decreased (0.36012 -> 0.34694). Saving model ...
Epoch: 5 cost time: 0.66016
Epoch: 5, Steps: 191 | Train Loss: 0.31281 Vali Loss: 0.34034
Validation loss decreased (0.34694 -> 0.34034). Saving model ...
Epoch: 6 cost time: 0.65893
Epoch: 6, Steps: 191 | Train Loss: 0.30569 Vali Loss: 0.32909
Validation loss decreased (0.34034 -> 0.32909). Saving model ...
Epoch: 7 cost time: 0.65823
Epoch: 7, Steps: 191 | Train Loss: 0.30441 Vali Loss: 0.32659
Validation loss decreased (0.32909 -> 0.32659). Saving model ...
Epoch: 8 cost time: 0.6585
Epoch: 8, Steps: 191 | Train Loss: 0.30188 Vali Loss: 0.33092
EarlyStopping counter: 1 out of 3
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch: 9 cost time: 0.66494
Epoch: 9, Steps: 191 | Train Loss: 0.29957 Vali Loss: 0.32896
EarlyStopping counter: 2 out of 3
Epoch 00009: reducing learning rate of group 0 to 1.0000e-05.
Epoch: 10 cost time: 0.66323
Epoch: 10, Steps: 191 | Train Loss: 0.30054 Vali Loss: 0.32681
EarlyStopping counter: 3 out of 3
Early stopping
Train ended. Total time 0:00:07.385514, per epoch 0:00:00.738551

Loading the best model from results/DLinear_Top_20/checkpoint.pth

>>>>>>> testing : DLinear_Top_20 <<<<<<<<
Preds and Trues shape: (20, 14, 1) (20, 14, 1)
test: rmse:1717.6, mae:949.37, msle: 2.7177, r2: 0.22656

Preds and Trues shape: (20, 14, 1) (20, 14, 1)
val: rmse:686.1, mae:383.85, msle: 2.8124, r2: 0.43476

Preds and Trues shape: (12200, 14, 1) (12200, 14, 1)
train: rmse:656.48, mae:302.78, msle: 2.011, r2: 0.70963

