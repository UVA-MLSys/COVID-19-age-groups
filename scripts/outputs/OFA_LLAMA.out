Experiment started at 2024-12-22 14:12:01.329412
Args in experiment:
Namespace(test=False, model='OFA', seed=7, root_path='./dataset/processed/', data_path='Total.csv', result_path='scratch', freq='d', no_scale=False, seq_len=14, label_len=7, pred_len=14, top_k=5, num_kernels=6, d_model=4096, n_heads=4, e_layers=2, d_layers=1, d_ff=256, moving_avg=7, factor=3, distil=True, dropout=0.3, embed='timeF', activation='gelu', output_attention=False, down_sampling_layers=0, down_sampling_window=1, decomp_method='moving_avg', channel_independence=1, down_sampling_method=None, use_norm=1, patch_len=7, num_workers=0, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0005, des='', loss='MSE', lradj='type1', use_amp=False, no_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[64, 64], p_hidden_layers=2, percent=10, disable_progress=False, gpt_layers=2, is_gpt=1, patch_size=7, pretrain=1, freeze=1, stride=1, max_len=-1, hid_dim=16, tmax=10, n_scale=-1, llm_model='LLAMA', n_features=10, enc_in=10, dec_in=10, c_out=10, n_targets=1)
Starting experiment. Result folder scratch/OFA_Total.
Use GPU: cuda:0
Getting the LLaMA model
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  4.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it]
